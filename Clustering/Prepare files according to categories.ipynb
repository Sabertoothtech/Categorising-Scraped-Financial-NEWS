{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare different files for each category of the news\n",
    "We have several categories of news from various sources. These include announcements, earnings, recommendations etc. We have to filter out the news according to these categories to understand better as to which news belonged to which category and which one would create a greater impact.\n",
    "\n",
    "We create a set which has a list included in it to get unique values of all the categories. Once we get all possible values of the categories, we create one file of each category and if the news was of that category, we append that row into that particular file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deals\n",
      "Education\n",
      "Budget\n",
      "Consumer\n",
      "Fintech\n",
      "International\n",
      "Cyber Risk\n",
      "ipl\n",
      "PF\n",
      "Opinion\n",
      "Current Affairs\n",
      "Finance\n",
      "politics\n",
      "Business News\n",
      "Sports\n",
      "Sports News\n",
      "Technology News\n",
      "Elections\n",
      "Companies\n",
      "World News\n",
      "Home Page\n",
      "business\n",
      "Brexit\n",
      "Economy & Policy\n",
      "U.S.\n",
      "Asia\n",
      "Top News\n",
      "Leisure\n",
      "Big Story 10\n",
      "Partner Content\n",
      "Markets\n",
      "Politics\n",
      "Full coverage of the Winter Olympics.\n",
      "Environment\n",
      "Entertainment News\n",
      "Health News\n",
      "Money\n",
      "Commodities\n",
      "markets\n",
      "technology\n",
      "Technology\n",
      "global-economics\n",
      "Foreign Exchange Analysis\n",
      "Science\n",
      "Science News\n",
      "Industry\n"
     ]
    }
   ],
   "source": [
    "#Make clusters according to categories\n",
    "\n",
    "import ast\n",
    "import sys\n",
    "import csv\n",
    "maxInt = sys.maxsize\n",
    "decrement = True\n",
    "\n",
    "while decrement:\n",
    "    decrement = False\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        decrement = True\n",
    "file = open(r'AllNews.csv','r',encoding='ISO-8859-1')\n",
    "read = csv.reader(file)\n",
    "master = set([])\n",
    "next(read,None)\n",
    "for i in read:\n",
    "    s1=i[2]\n",
    "    if('[' in s1 and ']' in s1):\n",
    "        s = ast.literal_eval(s1)\n",
    "        master = master | set(s)\n",
    "    else:\n",
    "        master.add(s1)\n",
    "file.close()\n",
    "for z in master:\n",
    "    print(z)\n",
    "for j in master:\n",
    "    if '/' in j:\n",
    "        j=j.replace(\"/\",\"\")\n",
    "    file1 = open(r'C:\\Users\\T\\Desktop\\Saber\\Filtering the News\\Clustering\\Clusters\\\\'+j+'.csv','a',newline='',encoding='ISO-8859-1')\n",
    "    write = csv.writer(file1)\n",
    "    write.writerow(['Unnamed','Source','Category','Date','Author','Title','Tags','Subtitle','Content'])\n",
    "    file = open(r'AllNews.csv','r',encoding='ISO-8859-1')\n",
    "    read = csv.reader(file)\n",
    "    next(read,None)\n",
    "    for i in read:\n",
    "        if j in i[2]:\n",
    "            write.writerow([i[0],i[1],i[2],i[3],i[4],i[5],i[6],i[7],i[8]])\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
